{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa43e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import eurostat\n",
    "\n",
    "# Import data using the Eurostat API\n",
    "data = eurostat.get_data_df('TOUR_CE_OMN12')\n",
    "\n",
    "#Drop columns'freq','unit'\n",
    "data.drop(columns=['freq','unit'], errors='ignore', inplace=True)\n",
    "\n",
    "#add column geo_layer to label geographic regions (NUTS codes).\n",
    "df = pd.DataFrame(data)\n",
    "df['geo_layer'] = df['geo\\TIME_PERIOD'].apply(lambda x: 'NUT1' if len(x) == 3 else ('NUT2' if len(x) == 4 else ('Country' if len(x) == 2 else '[EU27_2020]')))\n",
    "#put column \"geo\" besides column \"geo_layer\" \n",
    "col_order = ['geo\\TIME_PERIOD', 'geo_layer'] + [col for col in df.columns if col not in ['geo\\TIME_PERIOD', 'geo_layer']]\n",
    "df = df[col_order]\n",
    "\n",
    "#Drop row where 'c_resid' and 'month' value is total\n",
    "df = df[df['c_resid'] != 'TOTAL']\n",
    "df = df[df['month'] != 'TOTAL']\n",
    "\n",
    "#Change colomn label for 'geo\\TIME_PERIOD' to 'geo'\n",
    "df.columns.values[df.columns.get_loc('geo\\TIME_PERIOD')] = 'geo'\n",
    "\n",
    "long_df = pd.melt(df, id_vars=['geo', 'geo_layer', 'indic_to', 'c_resid', 'month'], value_vars=['2018', '2019', '2020', '2021', '2022', '2023', '2024'], var_name='Year', value_name='Value') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d95800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freq', 'indic_to', 'c_resid', 'month', 'unit', 'geo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check all parameter in dataset\n",
    "import eurostat\n",
    "pars = eurostat.get_pars('TOUR_CE_OMN12')\n",
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d255491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'indic_to' column: ['LSTY' 'NGT_SP' 'STY']\n",
      "Unique values in 'c_resid' column: ['DOM' 'FOR' 'TOTAL']\n",
      "Unique values in 'month' column: ['M01' 'M02' 'M03' 'M04' 'M05' 'M06' 'M07' 'M08' 'M09' 'M10' 'M11' 'M12'\n",
      " 'TOTAL']\n",
      "Unique values in 'TIME_PERIOD' column: ['AT' 'AT1' 'AT11' 'AT12' 'AT13' 'AT2' 'AT21' 'AT22' 'AT3' 'AT31' 'AT32'\n",
      " 'AT33' 'AT34' 'BE' 'BE1' 'BE10' 'BE2' 'BE21' 'BE22' 'BE23' 'BE24' 'BE25'\n",
      " 'BE3' 'BE31' 'BE32' 'BE33' 'BE34' 'BE35' 'BG' 'BG3' 'BG31' 'BG32' 'BG33'\n",
      " 'BG34' 'BG4' 'BG41' 'BG42' 'CH' 'CH0' 'CH01' 'CH02' 'CH03' 'CH04' 'CH05'\n",
      " 'CH06' 'CH07' 'CY' 'CY0' 'CY00' 'CZ' 'CZ0' 'CZ01' 'CZ02' 'CZ03' 'CZ04'\n",
      " 'CZ05' 'CZ06' 'CZ07' 'CZ08' 'DE' 'DE1' 'DE11' 'DE12' 'DE13' 'DE14' 'DE2'\n",
      " 'DE21' 'DE22' 'DE23' 'DE24' 'DE25' 'DE26' 'DE27' 'DE3' 'DE30' 'DE4'\n",
      " 'DE40' 'DE5' 'DE50' 'DE6' 'DE60' 'DE7' 'DE71' 'DE72' 'DE73' 'DE8' 'DE80'\n",
      " 'DE9' 'DE91' 'DE92' 'DE93' 'DE94' 'DEA' 'DEA1' 'DEA2' 'DEA3' 'DEA4'\n",
      " 'DEA5' 'DEB' 'DEB1' 'DEB2' 'DEB3' 'DEC' 'DEC0' 'DED' 'DED2' 'DED4' 'DED5'\n",
      " 'DEE' 'DEE0' 'DEF' 'DEF0' 'DEG' 'DEG0' 'DK' 'DK0' 'DK01' 'DK02' 'DK03'\n",
      " 'DK04' 'DK05' 'EE' 'EE0' 'EE00' 'EL' 'EL3' 'EL30' 'EL4' 'EL41' 'EL42'\n",
      " 'EL43' 'EL5' 'EL51' 'EL52' 'EL53' 'EL54' 'EL6' 'EL61' 'EL62' 'EL63'\n",
      " 'EL64' 'EL65' 'ES' 'ES1' 'ES11' 'ES12' 'ES13' 'ES2' 'ES21' 'ES22' 'ES23'\n",
      " 'ES24' 'ES3' 'ES30' 'ES4' 'ES41' 'ES42' 'ES43' 'ES5' 'ES51' 'ES52' 'ES53'\n",
      " 'ES6' 'ES61' 'ES62' 'ES63' 'ES64' 'ES7' 'ES70' 'EU27_2020' 'FI' 'FI1'\n",
      " 'FI19' 'FI1B' 'FI1C' 'FI1D' 'FI2' 'FI20' 'FR' 'FR1' 'FR10' 'FRB' 'FRB0'\n",
      " 'FRC' 'FRC1' 'FRC2' 'FRD' 'FRD1' 'FRD2' 'FRE' 'FRE1' 'FRE2' 'FRF' 'FRF1'\n",
      " 'FRF2' 'FRF3' 'FRG' 'FRG0' 'FRH' 'FRH0' 'FRI' 'FRI1' 'FRI2' 'FRI3' 'FRJ'\n",
      " 'FRJ1' 'FRJ2' 'FRK' 'FRK1' 'FRK2' 'FRL' 'FRL0' 'FRM' 'FRM0' 'FRY' 'FRY1'\n",
      " 'FRY2' 'FRY3' 'FRY4' 'FRY5' 'HR' 'HR0' 'HR02' 'HR03' 'HR05' 'HR06' 'HU'\n",
      " 'HU1' 'HU11' 'HU12' 'HU2' 'HU21' 'HU22' 'HU23' 'HU3' 'HU31' 'HU32' 'HU33'\n",
      " 'IE' 'IE0' 'IE04' 'IE05' 'IE06' 'IS' 'IS0' 'IS00' 'IT' 'ITC' 'ITC1'\n",
      " 'ITC2' 'ITC3' 'ITC4' 'ITF' 'ITF1' 'ITF2' 'ITF3' 'ITF4' 'ITF5' 'ITF6'\n",
      " 'ITG' 'ITG1' 'ITG2' 'ITH' 'ITH1' 'ITH2' 'ITH3' 'ITH4' 'ITH5' 'ITI' 'ITI1'\n",
      " 'ITI2' 'ITI3' 'ITI4' 'LI' 'LI0' 'LI00' 'LT' 'LT0' 'LT01' 'LT02' 'LU'\n",
      " 'LU0' 'LU00' 'LV' 'LV0' 'LV00' 'MT' 'MT0' 'MT00' 'NL' 'NL1' 'NL11' 'NL12'\n",
      " 'NL13' 'NL2' 'NL21' 'NL22' 'NL23' 'NL3' 'NL31' 'NL32' 'NL33' 'NL34' 'NL4'\n",
      " 'NL41' 'NL42' 'NO' 'NO0' 'NO02' 'NO06' 'NO07' 'NO08' 'NO09' 'NO0A' 'PL'\n",
      " 'PL2' 'PL21' 'PL22' 'PL4' 'PL41' 'PL42' 'PL43' 'PL5' 'PL51' 'PL52' 'PL6'\n",
      " 'PL61' 'PL62' 'PL63' 'PL7' 'PL71' 'PL72' 'PL8' 'PL81' 'PL82' 'PL84' 'PL9'\n",
      " 'PL91' 'PL92' 'PT' 'PT1' 'PT11' 'PT15' 'PT16' 'PT17' 'PT18' 'PT2' 'PT20'\n",
      " 'PT3' 'PT30' 'RO' 'RO1' 'RO11' 'RO12' 'RO2' 'RO21' 'RO22' 'RO3' 'RO31'\n",
      " 'RO32' 'RO4' 'RO41' 'RO42' 'SE' 'SE1' 'SE11' 'SE12' 'SE2' 'SE21' 'SE22'\n",
      " 'SE23' 'SE3' 'SE31' 'SE32' 'SE33' 'SI' 'SI0' 'SI03' 'SI04' 'SK' 'SK0'\n",
      " 'SK01' 'SK02' 'SK03' 'SK04']\n"
     ]
    }
   ],
   "source": [
    "#check whether there's special character like space in the value of dataset\n",
    "\n",
    "print(\"Unique values in 'indic_to' column:\", data['indic_to'].unique())\n",
    "print(\"Unique values in 'c_resid' column:\", data['c_resid'].unique())\n",
    "print(\"Unique values in 'month' column:\", data['month'].unique())\n",
    "print(\"Unique values in 'TIME_PERIOD' column:\", data['geo\\TIME_PERIOD'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5bbb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo              0\n",
      "geo_layer        0\n",
      "indic_to         0\n",
      "c_resid          0\n",
      "month            0\n",
      "Year             0\n",
      "Value        20886\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check null value amount for each column\n",
    "null_counts = long_df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6520055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where Value is NaN for Year 2024: 20790\n",
      "Number of rows where Value is NaN for Year 2023: 9\n",
      "Number of rows where Value is NaN for Year 2022: 9\n",
      "Number of rows where Value is NaN for Year 2021: 21\n",
      "Number of rows where Value is NaN for Year 2020: 15\n",
      "Number of rows where Value is NaN for Year 2019: 21\n",
      "Number of rows where Value is NaN for Year 2018: 21\n"
     ]
    }
   ],
   "source": [
    "#Analyse null value distribution\n",
    "#most of null value are in 2024,so we will not cover 2024 for later analyse\n",
    "#For year 2018-2024,the null value amount is small, so we will drop it for later analyse\n",
    "\n",
    "rows_2024 = long_df[long_df['Year'] == '2024']\n",
    "rows_2023 = long_df[long_df['Year'] == '2023']\n",
    "rows_2022 = long_df[long_df['Year'] == '2022']\n",
    "rows_2021 = long_df[long_df['Year'] == '2021']\n",
    "rows_2020 = long_df[long_df['Year'] == '2020']\n",
    "rows_2019 = long_df[long_df['Year'] == '2019']\n",
    "rows_2018 = long_df[long_df['Year'] == '2018']\n",
    "missing_value_count_2024 = rows_2024['Value'].isna().sum()\n",
    "missing_value_count_2023 = rows_2023['Value'].isna().sum()\n",
    "missing_value_count_2022 = rows_2022['Value'].isna().sum()\n",
    "missing_value_count_2021 = rows_2021['Value'].isna().sum()\n",
    "missing_value_count_2020 = rows_2020['Value'].isna().sum()\n",
    "missing_value_count_2019 = rows_2019['Value'].isna().sum()\n",
    "missing_value_count_2018 = rows_2018['Value'].isna().sum()\n",
    "print(f\"Number of rows where Value is NaN for Year 2024: {missing_value_count_2024}\")\n",
    "print(f\"Number of rows where Value is NaN for Year 2023: {missing_value_count_2023}\")\n",
    "print(f\"Number of rows where Value is NaN for Year 2022: {missing_value_count_2022}\")\n",
    "print(f\"Number of rows where Value is NaN for Year 2021: {missing_value_count_2021}\")\n",
    "print(f\"Number of rows where Value is NaN for Year 2020: {missing_value_count_2020}\")\n",
    "print(f\"Number of rows where Value is NaN for Year 2019: {missing_value_count_2019}\")\n",
    "print(f\"Number of rows where Value is NaN for Year 2018: {missing_value_count_2018}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9469aaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>geo_layer</th>\n",
       "      <th>indic_to</th>\n",
       "      <th>c_resid</th>\n",
       "      <th>month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>Country</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>DOM</td>\n",
       "      <td>M01</td>\n",
       "      <td>2018</td>\n",
       "      <td>23783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1</td>\n",
       "      <td>NUT1</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>DOM</td>\n",
       "      <td>M01</td>\n",
       "      <td>2018</td>\n",
       "      <td>8096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT11</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>DOM</td>\n",
       "      <td>M01</td>\n",
       "      <td>2018</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT12</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>DOM</td>\n",
       "      <td>M01</td>\n",
       "      <td>2018</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT13</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>DOM</td>\n",
       "      <td>M01</td>\n",
       "      <td>2018</td>\n",
       "      <td>7067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166315</th>\n",
       "      <td>SK0</td>\n",
       "      <td>NUT1</td>\n",
       "      <td>STY</td>\n",
       "      <td>FOR</td>\n",
       "      <td>M12</td>\n",
       "      <td>2023</td>\n",
       "      <td>18620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166316</th>\n",
       "      <td>SK01</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>STY</td>\n",
       "      <td>FOR</td>\n",
       "      <td>M12</td>\n",
       "      <td>2023</td>\n",
       "      <td>8896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166317</th>\n",
       "      <td>SK02</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>STY</td>\n",
       "      <td>FOR</td>\n",
       "      <td>M12</td>\n",
       "      <td>2023</td>\n",
       "      <td>1296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166318</th>\n",
       "      <td>SK03</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>STY</td>\n",
       "      <td>FOR</td>\n",
       "      <td>M12</td>\n",
       "      <td>2023</td>\n",
       "      <td>4891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166319</th>\n",
       "      <td>SK04</td>\n",
       "      <td>NUT2</td>\n",
       "      <td>STY</td>\n",
       "      <td>FOR</td>\n",
       "      <td>M12</td>\n",
       "      <td>2023</td>\n",
       "      <td>3537.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166224 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo geo_layer indic_to c_resid month  Year    Value\n",
       "0         AT   Country     LSTY     DOM   M01  2018  23783.0\n",
       "1        AT1      NUT1     LSTY     DOM   M01  2018   8096.0\n",
       "2       AT11      NUT2     LSTY     DOM   M01  2018    239.0\n",
       "3       AT12      NUT2     LSTY     DOM   M01  2018    790.0\n",
       "4       AT13      NUT2     LSTY     DOM   M01  2018   7067.0\n",
       "...      ...       ...      ...     ...   ...   ...      ...\n",
       "166315   SK0      NUT1      STY     FOR   M12  2023  18620.0\n",
       "166316  SK01      NUT2      STY     FOR   M12  2023   8896.0\n",
       "166317  SK02      NUT2      STY     FOR   M12  2023   1296.0\n",
       "166318  SK03      NUT2      STY     FOR   M12  2023   4891.0\n",
       "166319  SK04      NUT2      STY     FOR   M12  2023   3537.0\n",
       "\n",
       "[166224 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with any missing values\n",
    "long_df.dropna(inplace=True)\n",
    "# Drop rows where Year is 2024\n",
    "long_df = long_df[long_df['Year'] != '2024']\n",
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee099501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>c_resid</th>\n",
       "      <th>indic_to</th>\n",
       "      <th>geo_layer</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M01</td>\n",
       "      <td>DOM</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>Country</td>\n",
       "      <td>2018</td>\n",
       "      <td>2076982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M01</td>\n",
       "      <td>DOM</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>2517764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M01</td>\n",
       "      <td>DOM</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>Country</td>\n",
       "      <td>2020</td>\n",
       "      <td>3342210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M01</td>\n",
       "      <td>DOM</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>Country</td>\n",
       "      <td>2021</td>\n",
       "      <td>2425589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M01</td>\n",
       "      <td>DOM</td>\n",
       "      <td>LSTY</td>\n",
       "      <td>Country</td>\n",
       "      <td>2022</td>\n",
       "      <td>4108208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>M12</td>\n",
       "      <td>FOR</td>\n",
       "      <td>STY</td>\n",
       "      <td>[EU27_2020]</td>\n",
       "      <td>2019</td>\n",
       "      <td>1563624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>M12</td>\n",
       "      <td>FOR</td>\n",
       "      <td>STY</td>\n",
       "      <td>[EU27_2020]</td>\n",
       "      <td>2020</td>\n",
       "      <td>171960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>M12</td>\n",
       "      <td>FOR</td>\n",
       "      <td>STY</td>\n",
       "      <td>[EU27_2020]</td>\n",
       "      <td>2021</td>\n",
       "      <td>893514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>M12</td>\n",
       "      <td>FOR</td>\n",
       "      <td>STY</td>\n",
       "      <td>[EU27_2020]</td>\n",
       "      <td>2022</td>\n",
       "      <td>1548701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>M12</td>\n",
       "      <td>FOR</td>\n",
       "      <td>STY</td>\n",
       "      <td>[EU27_2020]</td>\n",
       "      <td>2023</td>\n",
       "      <td>2006631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month c_resid indic_to    geo_layer  Year      Value\n",
       "0      M01     DOM     LSTY      Country  2018  2076982.0\n",
       "1      M01     DOM     LSTY      Country  2019  2517764.0\n",
       "2      M01     DOM     LSTY      Country  2020  3342210.0\n",
       "3      M01     DOM     LSTY      Country  2021  2425589.0\n",
       "4      M01     DOM     LSTY      Country  2022  4108208.0\n",
       "...    ...     ...      ...          ...   ...        ...\n",
       "1723   M12     FOR      STY  [EU27_2020]  2019  1563624.0\n",
       "1724   M12     FOR      STY  [EU27_2020]  2020   171960.0\n",
       "1725   M12     FOR      STY  [EU27_2020]  2021   893514.0\n",
       "1726   M12     FOR      STY  [EU27_2020]  2022  1548701.0\n",
       "1727   M12     FOR      STY  [EU27_2020]  2023  2006631.0\n",
       "\n",
       "[1728 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarize data by month, guest residence, or geo_layer\n",
    "summary_df = long_df.groupby(['month', 'c_resid', 'indic_to', 'geo_layer','Year']).agg({\n",
    "    'Value': 'sum',\n",
    "}).reset_index()\n",
    "#summary_file = 'processed_data.xlsx'\n",
    "#summary_df.to_excel(summary_file, index=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a446c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "# Function to preprocess data and train the model\n",
    "def train_model(data):    \n",
    "# Convert month to numerical format for modeling    \n",
    "    data['month_num'] = data['month'].str.extract(r'M(\\d+)').astype(int)    \n",
    "# Select relevant features and target    \n",
    "    X = data[['Year', 'month_num', 'geo_layer', 'indic_to', 'c_resid']].copy()    \n",
    "    y = data['Value']    \n",
    "# One-hot encode categorical variables    \n",
    "    X = pd.get_dummies(X, columns=['geo_layer', 'indic_to', 'c_resid'], drop_first=True)    \n",
    "# Split data into training and testing sets    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    \n",
    "# Train a Random Forest Regressor    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)    \n",
    "    model.fit(X_train, y_train)    \n",
    "# Evaluate the model    \n",
    "    y_pred = model.predict(X_test)    \n",
    "    mse = mean_squared_error(y_test, y_pred)    \n",
    "    print(f\"Model Mean Squared Error: {mse}\")    \n",
    "    return model, X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c2014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict future trends\n",
    "def predict_future_trends(model, historical_data, years_to_predict=3):    \n",
    "    # Create a DataFrame for future predictions    \n",
    "    last_year = historical_data['Year'].max()    \n",
    "    future_years = list(range(last_year + 1, last_year + 1 + years_to_predict))    \n",
    "    # Generate rows for each combination of future year and month    \n",
    "    future_data = pd.DataFrame([(year, month) for year in future_years for month in range(1, 13)],                               \n",
    "                               columns=['Year', 'month_num'])    \n",
    "    # Add placeholders for categorical features    \n",
    "    future_data['geo_layer'] = historical_data['geo_layer'].iloc[0]    \n",
    "    future_data['indic_to'] = historical_data['indic_to'].iloc[0]    \n",
    "    future_data['c_resid'] = historical_data['c_resid'].iloc[0]    \n",
    "    # One-hot encode future data    \n",
    "    future_data = pd.get_dummies(future_data, columns=['geo_layer', 'indic_to', 'c_resid'], drop_first=True)    \n",
    "    # Align columns with training data    \n",
    "    for col in model.feature_names_in_:        \n",
    "        if col not in future_data.columns:            \n",
    "            future_data[col] = 0    \n",
    "            # Predict future trends    \n",
    "            future_data['Predicted_Value'] = model.predict(future_data)    \n",
    "            return future_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae6101f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fcc00f36100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 1067667743298.5035\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Make sure this DataFrame is defined and contains relevant data\n",
    "# summary_df = pd.read_csv('your_data_here.csv')\n",
    "\n",
    "# Sample layout for the app\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(id='geo_layer-dropdown', options=[\n",
    "        {'label': geo, 'value': geo} for geo in summary_df['geo_layer'].unique()\n",
    "    ], value='Country'),\n",
    "    dcc.Dropdown(id='indic_to-dropdown', options=[\n",
    "        {'label': indic, 'value': indic} for indic in summary_df['indic_to'].unique()\n",
    "    ], value='LSTY'),\n",
    "    dcc.Dropdown(id='c_resid-dropdown', options=[\n",
    "        {'label': resid, 'value': resid} for resid in summary_df['c_resid'].unique()\n",
    "    ], value='DOM'),\n",
    "    dcc.Graph(id='prediction_chart')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('prediction_chart', 'figure'),\n",
    "    [Input('geo_layer-dropdown', 'value'),\n",
    "     Input('indic_to-dropdown', 'value'),\n",
    "     Input('c_resid-dropdown', 'value')]\n",
    ")\n",
    "def update_prediction_chart(selected_geo_layer, selected_indic_to, selected_c_resid):\n",
    "    # Filter data for training\n",
    "    filtered_df = summary_df[\n",
    "        (summary_df['geo_layer'] == selected_geo_layer) &\n",
    "        (summary_df['indic_to'] == selected_indic_to) &\n",
    "        (summary_df['c_resid'] == selected_c_resid)\n",
    "    ].copy()\n",
    "\n",
    "    # Check if filtered_df is empty\n",
    "    if filtered_df.empty:\n",
    "        return px.line(title=\"No data available for the selected filters.\")\n",
    "\n",
    "    try:\n",
    "        # Ensure the train_model and predict_future_trends functions are defined\n",
    "        model = train_model(filtered_df)  # Replace with your actual implementation\n",
    "        \n",
    "        # Assume predict_future_trends returns a DataFrame with 'month_num' and 'Predicted_Value'\n",
    "        future_predictions = predict_future_trends(model, filtered_df)\n",
    "        \n",
    "        # Ensure 'month' is created correctly for future predictions\n",
    "        if 'month_num' in future_predictions.columns:\n",
    "            future_predictions['month'] = future_predictions['month_num'].apply(lambda x: f\"M{int(x):02d}\")\n",
    "            future_predictions = future_predictions.rename(columns={'Predicted_Value': 'Value'})\n",
    "            future_predictions['Type'] = 'Predicted'\n",
    "        else:\n",
    "            raise ValueError(\"Column 'month_num' not found in predictions.\")\n",
    "\n",
    "        # Prepare historical data for plotting\n",
    "        historical_data = filtered_df[['Year', 'month', 'Value']].copy()\n",
    "        historical_data['Type'] = 'Historical'\n",
    "\n",
    "        # Concatenate historical and predicted data\n",
    "        combined_data = pd.concat([historical_data, future_predictions], ignore_index=True)\n",
    "\n",
    "        # Create a line chart\n",
    "        fig = px.line(\n",
    "            combined_data,\n",
    "            x='month',\n",
    "            y='Value',\n",
    "            color='Type',\n",
    "            line_group='Year',\n",
    "            title=f\"Predicted Trends for {selected_geo_layer}, {selected_indic_to}, {selected_c_resid}\",\n",
    "            labels={'Value': 'Accommodation Demand'}\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        return px.line(title=f\"Error: {str(e)}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c966dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
